{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b577f9d2",
   "metadata": {},
   "source": [
    "\n",
    "# CNN on MNIST â€” Teaching Notebook (Statistics PhD)\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Loading MNIST and visualizing samples\n",
    "- Training a **baseline MLP** vs a **CNN**\n",
    "- Tracking loss/accuracy\n",
    "- Confusion matrix visualization\n",
    "- Simple **data augmentation** experiment\n",
    "- Inspecting learned **convolutional filters**\n",
    "\n",
    "> **Note:** The first time you run this, `torchvision` will download MNIST automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad854301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup & configuration ---\n",
    "import os, sys, math, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# Hyperparameters (feel free to tweak)\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "EPOCHS_BASELINE = 3   # quick baseline\n",
    "EPOCHS_CNN = 5        # slightly longer for CNN\n",
    "VAL_SPLIT = 0.1       # 10% validation\n",
    "AUGMENT = False       # turn on to try augmentation\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ae9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Data: MNIST ---\n",
    "transform_list = [transforms.ToTensor()]\n",
    "if AUGMENT:\n",
    "    transform_list = [\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(0, translate=(0.05, 0.05)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "data_root = \"./data\"\n",
    "train_full = datasets.MNIST(root=data_root, train=True, transform=transform, download=True)\n",
    "test_set  = datasets.MNIST(root=data_root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Train/Val split\n",
    "val_size = int(len(train_full) * VAL_SPLIT)\n",
    "train_size = len(train_full) - val_size\n",
    "train_set, val_set = random_split(train_full, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "len(train_set), len(val_set), len(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b77a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Visualize a mini-batch ---\n",
    "imgs, labels = next(iter(train_loader))\n",
    "grid = utils.make_grid(imgs[:36], nrow=6, padding=2)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(grid.permute(1,2,0).squeeze())\n",
    "plt.axis('off')\n",
    "plt.title(\"MNIST samples\")\n",
    "plt.show()\n",
    "labels[:36]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bd11e",
   "metadata": {},
   "source": [
    "## Baseline: MLP (fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "mlp = MLP().to(device)\n",
    "sum(p.numel() for p in mlp.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e49ff",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab058cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # [B, 32, 28, 28]\n",
    "        x = self.pool(x)            # [B, 32, 14, 14]\n",
    "        x = F.relu(self.conv2(x))   # [B, 64, 14, 14]\n",
    "        x = self.pool(x)            # [B, 64, 7, 7]\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)     # [B, 64*7*7]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cnn = SimpleCNN().to(device)\n",
    "sum(p.numel() for p in cnn.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85e322",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a80aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(logits, y):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == y).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        bs = y.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc  += (logits.argmax(1) == y).float().sum().item()\n",
    "        total_n    += bs\n",
    "    return total_loss/total_n, total_acc/total_n\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=5, lr=1e-3):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss, running_correct, running_total = 0.0, 0, 0\n",
    "        t0 = time.time()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item() * y.size(0)\n",
    "            running_correct += (logits.argmax(1) == y).float().sum().item()\n",
    "            running_total += y.size(0)\n",
    "        tr_loss = running_loss / running_total\n",
    "        tr_acc  = running_correct / running_total\n",
    "        va_loss, va_acc = evaluate(model, val_loader, loss_fn)\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"train_acc\"].append(tr_acc)\n",
    "        history[\"val_loss\"].append(va_loss)\n",
    "        history[\"val_acc\"].append(va_acc)\n",
    "        t1 = time.time()\n",
    "        print(f\"Epoch {ep:02d} | \"\n",
    "              f\"train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
    "              f\"val loss {va_loss:.4f} acc {va_acc:.4f} | \"\n",
    "              f\"{t1-t0:.1f}s\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae0ea1",
   "metadata": {},
   "source": [
    "## Train Baseline MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa65ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp = MLP().to(device)\n",
    "hist_mlp = train_model(mlp, train_loader, val_loader, epochs=EPOCHS_BASELINE, lr=LR)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist_mlp[\"train_loss\"], label=\"train loss\")\n",
    "plt.plot(hist_mlp[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.title(\"MLP Loss\"); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist_mlp[\"train_acc\"], label=\"train acc\")\n",
    "plt.plot(hist_mlp[\"val_acc\"], label=\"val acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.legend(); plt.title(\"MLP Accuracy\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee42a5",
   "metadata": {},
   "source": [
    "## Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb44fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn = SimpleCNN().to(device)\n",
    "hist_cnn = train_model(cnn, train_loader, val_loader, epochs=EPOCHS_CNN, lr=LR)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist_cnn[\"train_loss\"], label=\"train loss\")\n",
    "plt.plot(hist_cnn[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.title(\"CNN Loss\"); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist_cnn[\"train_acc\"], label=\"train acc\")\n",
    "plt.plot(hist_cnn[\"val_acc\"], label=\"val acc\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.legend(); plt.title(\"CNN Accuracy\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55bc31",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_all(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().numpy().tolist()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "y_true, y_pred = predict_all(cnn, test_loader)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix (CNN)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, tick_marks)\n",
    "plt.yticks(tick_marks, tick_marks)\n",
    "thresh = cm.max() / 2\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "(test_acc := (y_true == y_pred).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc8146",
   "metadata": {},
   "source": [
    "## Inspect First-Layer Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    w = cnn.conv1.weight.cpu().clone()  # [32, 1, 3, 3]\n",
    "w = (w - w.min()) / (w.max() - w.min() + 1e-8)\n",
    "\n",
    "grid = utils.make_grid(w, nrow=8, padding=1, normalize=False)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(grid.permute(1,2,0).squeeze())\n",
    "plt.axis('off')\n",
    "plt.title(\"Conv1 filters (normalized)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fdd528",
   "metadata": {},
   "source": [
    "## Save & Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b797ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_path = \"cnn_mnist_ckpt.pt\"\n",
    "torch.save({\"model_state\": cnn.state_dict()}, ckpt_path)\n",
    "print(f\"Saved to {ckpt_path}\")\n",
    "\n",
    "# Example: reload\n",
    "cnn2 = SimpleCNN().to(device)\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "cnn2.load_state_dict(state[\"model_state\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca6b38",
   "metadata": {},
   "source": [
    "\n",
    "## Try Data Augmentation\n",
    "To try augmentation, set `AUGMENT = True` in the setup cell and re-run the notebook.  \n",
    "Then compare validation/test accuracy curves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823c9eb",
   "metadata": {},
   "source": [
    "## Parameter Count Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"MLP params:\", count_params(MLP()))\n",
    "print(\"CNN params:\", count_params(SimpleCNN()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfafc54",
   "metadata": {},
   "source": [
    "## Playground: Quick Re-run Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change LR / epochs here and rerun this cell and the training cells\n",
    "LR = 5e-4\n",
    "EPOCHS_CNN = 3\n",
    "print(\"LR:\", LR, \"EPOCHS_CNN:\", EPOCHS_CNN)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}